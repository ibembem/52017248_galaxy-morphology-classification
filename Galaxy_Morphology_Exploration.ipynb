{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyP4QY27KM2vc+FCCWD4t8nu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Library Imports and Setup"],"metadata":{"id":"-0NluvCZJmFl"}},{"cell_type":"code","source":["import os\n","import h5py\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","\n","# --- 2. Tensorflow and keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, Model, load_model\n","from tensorflow.keras.layers import (\n","    Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n","    BatchNormalization, GlobalAveragePooling2D\n",")\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# --- 3. Architectures and preprocessing\n","from tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB5\n","from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n","from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n","from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n","\n","# --- 4. Metrics etc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, f1_score\n","from sklearn.utils import class_weight\n","\n","print(f\"TensorFlow Version: {tf.__version__}\")\n","print(\"All necessary libraries imported successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UluqiFMwJiUs","executionInfo":{"status":"ok","timestamp":1765911922004,"user_tz":-60,"elapsed":9089,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"5fa01261-4535-423a-e220-863e086c9755"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow Version: 2.19.0\n","All necessary libraries imported successfully.\n"]}]},{"cell_type":"markdown","source":["So here we can see that the models do same errors in the same places and do not perform significantly deifferently."],"metadata":{"id":"wJ-Ypr6gFEpI"}},{"cell_type":"markdown","source":["# 2. Mount Google Drive"],"metadata":{"id":"L5CGt4EuJ5b2"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZJP9R4cHO-D6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765911945003,"user_tz":-60,"elapsed":19706,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"0d848e3f-5c1c-4231-8423-b54e4a1ba7a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Google Drive mounted successfully.\n","Project path defined: /content/drive/MyDrive/Galaxy_Morphology_Project\n","Models will be stored in: /content/drive/MyDrive/Galaxy_Morphology_Project/models\n"]}],"source":["# CONNECT GOOGLE DRIVE\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","print(\"Google Drive mounted successfully.\")\n","\n","DRIVE_PATH = '/content/drive/MyDrive/Galaxy_Morphology_Project'\n","MODEL_DIR = os.path.join(DRIVE_PATH, 'models')\n","\n","!mkdir -p {MODEL_DIR}\n","# Optional: !mkdir -p {os.path.join(DRIVE_PATH, 'logs')}\n","\n","print(f\"Project path defined: {DRIVE_PATH}\")\n","print(f\"Models will be stored in: {MODEL_DIR}\")"]},{"cell_type":"code","source":["# DATA LOADING, NORMALIZATION AND STRATIFIED SPLIT\n","\n","# 1. Load data from local VM storage\n","try:\n","    with h5py.File('data/Galaxy10.h5', 'r') as f:\n","        images = np.array(f['images'])\n","        labels = np.array(f['ans']) # Using 'ans' key for labels\n","except Exception as e:\n","    print(f\"Error reading file: {e}\")\n","    exit()\n","\n","# 2. Image Normalization\n","# Convert to float32 and scale to [0, 1] range\n","images = images.astype('float32') / 255.0\n","\n","# 3. One-Hot Encoding for labels\n","NUM_CLASSES = 10\n","labels_ohe = to_categorical(labels, num_classes=NUM_CLASSES)\n","\n","# 4. Stratified Data Split: Train (70%) / Validation (15%) / Test (15%)\n","# Stratification is critical due to the significant class imbalance in Galaxy10.\n","\n","X_train_val, X_test, y_train_val_ohe, y_test_ohe = train_test_split(\n","    images, labels_ohe, test_size=0.15, random_state=42, stratify=labels\n",")\n","\n","# Split ratio: 0.15 / 0.85 ≈ 0.1765\n","X_train, X_val, y_train_ohe, y_val_ohe = train_test_split(\n","    X_train_val, y_train_val_ohe, test_size=(0.15 / 0.85),\n","    random_state=42,\n","    stratify=np.argmax(y_train_val_ohe, axis=1)\n",")\n","\n","print(\"\\n--- Dataset Sizes ---\")\n","print(f\"Train Set:      {X_train.shape[0]} images\")\n","print(f\"Validation Set: {X_val.shape[0]} images\")\n","print(f\"Test Set:       {X_test.shape[0]} images\")\n","print(f\"Original Shape: {X_train.shape[1:]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WA0y89dfMSOW","executionInfo":{"status":"ok","timestamp":1765912543820,"user_tz":-60,"elapsed":59498,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"c6acdd4a-7839-42e8-cd32-754d76d71f69"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Dataset Sizes ---\n","Train Set:      12414 images\n","Validation Set: 2661 images\n","Test Set:       2661 images\n","Original Shape: (256, 256, 3)\n"]}]},{"cell_type":"markdown","source":["# 1. Vanilla CNN exploration"],"metadata":{"id":"Sjxz82bWqDUE"}},{"cell_type":"code","source":["# CUSTOM VANILLA CNN ARCHITECTURE ---\n","# This was the initial experiment using a custom-built CNN architecture\n","# to establish a baseline without using pre-trained weights.\n","# Configuration used during training\n","INPUT_SHAPE = (256, 256, 3)\n","NUM_CLASSES = 10\n","BATCH_SIZE = 32\n","EPOCHS_TRAINED = 20\n","\n","baseline_model = Sequential([\n","    # Block 1: 32 filters, BatchNormalization for faster convergence\n","    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),\n","    BatchNormalization(),\n","    MaxPooling2D((2, 2)),\n","    Dropout(0.25),\n","\n","    # Block 2: 64 filters\n","    Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    MaxPooling2D((2, 2)),\n","    Dropout(0.25),\n","\n","    # Block 3: 128 filters\n","    Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    MaxPooling2D((2, 2)),\n","    Dropout(0.25),\n","\n","    # Classification Head\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(NUM_CLASSES, activation='softmax')\n","])\n","\n","baseline_model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","print(\"Custom Vanilla CNN architecture defined.\")"],"metadata":{"id":"3-vWZUbioBEZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765913711287,"user_tz":-60,"elapsed":87,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"8a541765-0c9a-4b81-af33-dfa5be918e76"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Custom Vanilla CNN architecture defined.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","source":["# EVALUATING THE BASELINE MODEL\n","\n","BASELINE_FILE = os.path.join(MODEL_DIR, 'baseline_checkpoint.h5')\n","\n","try:\n","    # We load the weights into our defined architecture or load the whole model\n","    baseline_model = load_model(BASELINE_FILE)\n","    print(f\"Successfully loaded baseline model from: {BASELINE_FILE}\")\n","\n","    y_pred_probs = baseline_model.predict(X_test, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- BASELINE MODEL PERFORMANCE ---\")\n","    print(f\"Weighted F1-Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\"Error loading model: {e}\")"],"metadata":{"id":"E9sOqJrToBHB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765913809379,"user_tz":-60,"elapsed":5435,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"15197625-5dd6-4b65-e3ea-97d97e990955"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Successfully loaded baseline model from: /content/drive/MyDrive/Galaxy_Morphology_Project/models/baseline_checkpoint.h5\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step\n","\n","--- BASELINE MODEL PERFORMANCE ---\n","Weighted F1-Score: 0.0952\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.0788    0.0802    0.0795       162\n","           1     0.2353    0.0144    0.0271       278\n","           2     0.1967    0.6599    0.3031       397\n","           3     0.1094    0.0230    0.0380       304\n","           4     0.0000    0.0000    0.0000        50\n","           5     0.0864    0.0228    0.0361       307\n","           6     0.0791    0.0401    0.0533       274\n","           7     0.1360    0.2944    0.1860       394\n","           8     0.0000    0.0000    0.0000       214\n","           9     0.1250    0.0036    0.0069       281\n","\n","    accuracy                         0.1582      2661\n","   macro avg     0.1047    0.1139    0.0730      2661\n","weighted avg     0.1227    0.1582    0.0952      2661\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["**Low Training Accuracy (Train Accuracy ≈ 16%):**\n","The model performs only slightly better than random guessing (10%), even on the training data. This indicates that the model either lacks sufficient capacity or is not properly optimized to extract meaningful features from high-resolution 256×256 images."],"metadata":{"id":"GoFsPKmpkhJ5"}},{"cell_type":"markdown","source":["# 2. ResNet50\n","## Experiment 1: Training the Classification Head\n","\n","In this stage, we transition from a custom CNN to ResNet50. To preserve the pre-trained ImageNet features, we freeze the base model layers and only train a custom classification head. We also introduce Class Weights to address the significant dataset imbalance."],"metadata":{"id":"LLSc-FznrbyM"}},{"cell_type":"code","source":["# RESNET50 HEAD ARCHITECTURE SETUP\n","\n","# 1. Initialize ResNet50 with ImageNet weights (excluding top layer)\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n","\n","# 2. Freeze the base model layers\n","base_model.trainable = False\n","\n","# 3. Add Custom Classification Head\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n","\n","model_resnet_head = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 4. Compile with a standard Learning Rate for the initial head training\n","model_resnet_head.compile(\n","    optimizer=Adam(learning_rate=1e-3),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# 5. Class Weight Calculation\n","y_train_labels = np.argmax(y_train_ohe, axis=1)\n","weights = class_weight.compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(y_train_labels),\n","    y=y_train_labels\n",")\n","CLASS_WEIGHTS_DICT = dict(enumerate(weights))\n","\n","print(\"ResNet50 head architecture defined.\")\n","print(f\"Calculated Class Weights: {CLASS_WEIGHTS_DICT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRpEsVFsrlkB","executionInfo":{"status":"ok","timestamp":1765914082997,"user_tz":-60,"elapsed":1083,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"c621f08b-8dac-4aea-88d7-20aec6f564f2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":[" ResNet50 head architecture defined.\n","Calculated Class Weights: {0: np.float64(1.639894319682959), 1: np.float64(0.9571318427139552), 2: np.float64(0.6706645056726094), 3: np.float64(0.8748414376321353), 4: np.float64(5.305128205128205), 5: np.float64(0.8687193841847446), 6: np.float64(0.96984375), 7: np.float64(0.6746739130434782), 8: np.float64(1.2463855421686747), 9: np.float64(0.9469107551487415)}\n"]}]},{"cell_type":"code","source":["# EVALUATING\n","\n","# File: resnet50_head_trained.h5 (Trained for 5 epochs)\n","\n","HEAD_MODEL_PATH = os.path.join(MODEL_DIR, 'resnet50_head_trained.h5')\n","\n","try:\n","    # Load the model state after the first 5 epochs\n","    model_resnet_head = load_model(HEAD_MODEL_PATH)\n","    print(f\"Successfully loaded head-trained model from: {HEAD_MODEL_PATH}\")\n","\n","    # Using raw X_test (normalized to [0,1])\n","    y_pred_probs = model_resnet_head.predict(X_test, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- RESNET50 HEAD-ONLY PERFORMANCE ---\")\n","    print(f\"Weighted F1-Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n","    print(\"\\nClassification Report (Focus on rare classes improvement):\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\"Error loading head model: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8F93gjgMrsyu","executionInfo":{"status":"ok","timestamp":1765914144800,"user_tz":-60,"elapsed":26531,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"fe07db7a-c11c-4bed-92ed-ca6fd3aeb62e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Successfully loaded head-trained model from: /content/drive/MyDrive/Galaxy_Morphology_Project/models/resnet50_head_trained.h5\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 100ms/step\n","\n","--- RESNET50 HEAD-ONLY PERFORMANCE ---\n","Weighted F1-Score: 0.0192\n","\n","Classification Report (Focus on rare classes improvement):\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000       162\n","           1     0.0000    0.0000    0.0000       278\n","           2     0.0000    0.0000    0.0000       397\n","           3     0.0000    0.0000    0.0000       304\n","           4     0.0000    0.0000    0.0000        50\n","           5     0.0000    0.0000    0.0000       307\n","           6     0.1030    1.0000    0.1867       274\n","           7     0.0000    0.0000    0.0000       394\n","           8     0.0000    0.0000    0.0000       214\n","           9     0.0000    0.0000    0.0000       281\n","\n","    accuracy                         0.1030      2661\n","   macro avg     0.0103    0.1000    0.0187      2661\n","weighted avg     0.0106    0.1030    0.0192      2661\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["## Experiment 2: Technical Insight — Fixing Input\n","During initial ResNet50 trials, the model failed to converge (Accuracy ~0.10).\n","\n","I identified that the pre-trained weights require specific ImageNet-style normalization (centering and scaling pixel values) provided by resnet_preprocess. Simply scaling to $[0, 1]$ was insufficient, I reverted the images to $[0, 255]$ and applied the official preprocessing."],"metadata":{"id":"PIXjwY56sWrL"}},{"cell_type":"code","source":["# CORRECTING PREPROCESSING FOR IMAGENET WEIGHTS\n","\n","# We revert normalized [0, 1] data back to [0, 255] for the official preprocessor\n","# Using the split data from Section 1.4\n","X_train_val_raw = X_train_val * 255.0\n","X_test_raw = X_test * 255.0\n","\n","# Apply ImageNet normalization (Mean subtraction and scaling)\n","X_train_val_processed = resnet_preprocess(X_train_val_raw)\n","X_test_processed = resnet_preprocess(X_test_raw)\n","\n","# Re-split Train and Validation with correctly processed data\n","X_train, X_val, y_train_ohe, y_val_ohe = train_test_split(\n","    X_train_val_processed, y_train_val_ohe,\n","    test_size=(0.15 / 0.85),\n","    random_state=42,\n","    stratify=np.argmax(y_train_val_ohe, axis=1)\n",")\n","\n","print(\"Data successfully re-processed using ImageNet standards.\")\n","print(f\"Sample pixel value after ResNet preprocessing: {X_train[0,0,0,0]:.2f}\")\n","# (Values will now be centered around zero, not 0-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AINGmXgTkpQM","executionInfo":{"status":"ok","timestamp":1765914332449,"user_tz":-60,"elapsed":18040,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"a3d04de7-f8d4-469b-b1a8-6b7898028f53"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Data successfully re-processed using ImageNet standards.\n","Sample pixel value after ResNet preprocessing: -76.94\n"]}]},{"cell_type":"markdown","source":["\n","After applying the resnet_preprocess function, we re-evaluated the head-trained model. The difference was dramatic: the model immediately regained its ability to recognize features, jumping from random guessing to meaningful classification.\n","\n","Evaluation with Proper Preprocessing:"],"metadata":{"id":"fiyytzkUsvzh"}},{"cell_type":"code","source":["# EVALUATION\n","# test the 'resnet50_head_trained.h5' model again\n","# but this time using the correctly preprocessed X_test_processed.\n","\n","try:\n","    y_pred_probs = model_resnet_head.predict(X_test_processed, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- RESULTS AFTER CORRECT PREPROCESSING ---\")\n","    current_f1 = f1_score(y_true, y_pred, average='weighted')\n","    print(f\"Weighted F1-Score: {current_f1:.4f}\")\n","    print(f\"Improvement over random guessing: +{(current_f1 - 0.1) * 100:.2f}%\")\n","\n","    print(\"\\nClassification Report (Baseline Transfer Learning):\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\"Error during evaluation: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpIDZw_Ms3W4","executionInfo":{"status":"ok","timestamp":1765914422306,"user_tz":-60,"elapsed":4588,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"dedddfeb-0aaf-48f7-de49-35416a42beed"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n","\n","--- RESULTS AFTER CORRECT PREPROCESSING ---\n","Weighted F1-Score: 0.5534\n","Improvement over random guessing: +45.34%\n","\n","Classification Report (Baseline Transfer Learning):\n","              precision    recall  f1-score   support\n","\n","           0     0.1818    0.2716    0.2178       162\n","           1     0.4733    0.4784    0.4758       278\n","           2     0.7587    0.6020    0.6713       397\n","           3     0.5570    0.5461    0.5515       304\n","           4     0.5192    0.5400    0.5294        50\n","           5     0.5588    0.4332    0.4881       307\n","           6     0.5146    0.5146    0.5146       274\n","           7     0.4197    0.4645    0.4410       394\n","           8     0.7909    0.8131    0.8018       214\n","           9     0.7115    0.7722    0.7406       281\n","\n","    accuracy                         0.5475      2661\n","   macro avg     0.5486    0.5436    0.5432      2661\n","weighted avg     0.5655    0.5475    0.5534      2661\n","\n"]}]},{"cell_type":"markdown","source":[" ## Experiment 3: Learning Rate: Fine-Tuning\n","  After successfully training the classification head, I unfroze the entire ResNet50 backbone. To prevent destroying the pre-trained features during this phase, I used a significantly lower learning rate ($10^{-5}$). This allows the model to subtly adjust the internal filters to better recognize specific galaxy morphologies while retaining the general knowledge from ImageNet."],"metadata":{"id":"uusQjf-9tiCq"}},{"cell_type":"code","source":["# CONFIGURATION\n","\n","# 1. Unfreeze all layers of the backbone\n","for layer in model_resnet_head.layers:\n","    layer.trainable = True\n","\n","# Low LR is critical during fine-tuning to maintain stability\n","NEW_LEARNING_RATE = 1e-5\n","\n","model_resnet_head.compile(\n","    optimizer=Adam(learning_rate=NEW_LEARNING_RATE),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Configuration used during this stage:\n","# Batch Size: 8 (reduced to prevent Out-Of-Memory errors during full backpropagation)\n","# Epochs: 20\n","print(f\"ResNet50 unfrozen and re-compiled with LR={NEW_LEARNING_RATE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KPXkJw1tz41","executionInfo":{"status":"ok","timestamp":1765914664015,"user_tz":-60,"elapsed":13,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"76f4eaf1-ba5d-4ec8-d6a8-163bdc3871f5"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet50 unfrozen and re-compiled with LR=1e-05\n"]}]},{"cell_type":"code","source":["# Evaluation\n","# File: resnet50_final_fine_tuned.h5\n","\n","FINE_TUNED_PATH = os.path.join(MODEL_DIR, 'resnet50_final_fine_tuned.h5')\n","\n","try:\n","    # Load the model after the full 20-epoch fine-tuning session\n","    model_resnet_final = load_model(FINE_TUNED_PATH)\n","    print(f\"Loaded fine-tuned ResNet50: {FINE_TUNED_PATH}\")\n","\n","    # Final evaluation on correctly preprocessed test data\n","    y_pred_probs = model_resnet_final.predict(X_test_processed, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- FINAL FINE-TUNED RESNET50 PERFORMANCE ---\")\n","    fine_tuned_f1 = f1_score(y_true, y_pred, average='weighted')\n","    print(f\"Weighted F1-Score: {fine_tuned_f1:.4f}\")\n","\n","    # We document the jump in performance from Phase 1 to Phase 2\n","    print(f\"Improvement from Fine-Tuning: +{(fine_tuned_f1 - current_f1):.4f}\")\n","\n","    print(\"\\nDetailed Classification Report:\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\"Error loading fine-tuned model: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqrze3T3t3lR","executionInfo":{"status":"ok","timestamp":1765914700891,"user_tz":-60,"elapsed":18053,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"03eaacca-1d1f-4857-ce83-febc72b750dc"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded fine-tuned ResNet50: /content/drive/MyDrive/Galaxy_Morphology_Project/models/resnet50_final_fine_tuned.h5\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step\n","\n","--- FINAL FINE-TUNED RESNET50 PERFORMANCE ---\n","Weighted F1-Score: 0.8001\n","Improvement from Fine-Tuning: +0.2467\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.4839    0.4630    0.4732       162\n","           1     0.8776    0.7734    0.8222       278\n","           2     0.9093    0.9345    0.9217       397\n","           3     0.8889    0.8947    0.8918       304\n","           4     0.6667    0.7200    0.6923        50\n","           5     0.8253    0.7850    0.8047       307\n","           6     0.7069    0.7482    0.7270       274\n","           7     0.6800    0.6472    0.6632       394\n","           8     0.8869    0.9159    0.9011       214\n","           9     0.8476    0.9502    0.8960       281\n","\n","    accuracy                         0.8016      2661\n","   macro avg     0.7773    0.7832    0.7793      2661\n","weighted avg     0.8004    0.8016    0.8001      2661\n","\n"]}]},{"cell_type":"markdown","source":["## Experiment 4: Optimization — Resolution Change & Regularization\n","\n","Resolution Adjustment and Dropout Tuning (V4).\n","\n","To optimize training speed and memory usage I shifted the input resolution from 256x256 to 128x128, as observed overfitting in previous runs, I implemented a more aggressive Dropout (0.4) in the classification head to improve generalization on the test set.\n","\n","**Backbone:** ResNet50 (Full Fine-Tuning).\n","\n","**Key change:** Added Dropout(0.4) after Global Average Pooling.\n","\n","**Training:** 10 epochs, Adam (LR 1e-5), Balanced Class Weights."],"metadata":{"id":"IlFvdOf7uv8E"}},{"cell_type":"code","source":["# OPTIMIZED RESNET50 (V4) ARCHITECTURE\n","# input size changed to 128x128 for better efficiency\n","TARGET_SIZE = 128\n","\n","base_model_v4 = ResNet50(weights='imagenet', include_top=False, input_shape=(TARGET_SIZE, TARGET_SIZE, 3))\n","base_model_v4.trainable = True # Full fine-tuning enabled\n","\n","x = GlobalAveragePooling2D()(base_model_v4.output)\n","x = Dropout(0.4)(x) # increased dropout for better regularization\n","predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n","\n","model_resnet_v4 = Model(inputs=base_model_v4.input, outputs=predictions)\n","\n","model_resnet_v4.compile(\n","    optimizer=Adam(learning_rate=1e-5),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","print(f\"Optimized ResNet50 (V4) defined for {TARGET_SIZE}x{TARGET_SIZE} input.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mD4L66OAL9Ll","executionInfo":{"status":"ok","timestamp":1765914938046,"user_tz":-60,"elapsed":1144,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"8019a0bd-7f7e-4df5-840f-8a86b6eb793e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimized ResNet50 (V4) defined for 128x128 input.\n"]}]},{"cell_type":"code","source":["# EVALUATING RESNET50 dropout\n","# File: resnet50_best_dropout_v4.keras\n","\n","RESNET_V4_PATH = os.path.join(MODEL_DIR, 'resnet50_best_dropout_v4.keras')\n","\n","try:\n","    # load the best weights for this specific architecture\n","    model_resnet_v4 = load_model(RESNET_V4_PATH)\n","    print(f\"Loaded ResNet50 V4: {RESNET_V4_PATH}\")\n","\n","    # resize X_test to 128x128 for this specific model\n","    import cv2\n","    X_test_128 = np.array([cv2.resize(img, (TARGET_SIZE, TARGET_SIZE)) for img in X_test_raw])\n","    X_test_128_processed = resnet_preprocess(X_test_128)\n","\n","    y_pred_probs = model_resnet_v4.predict(X_test_128_processed, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- RESNET50 V4 PERFORMANCE (128x128) ---\")\n","    v4_f1 = f1_score(y_true, y_pred, average='weighted')\n","    print(f\"Weighted F1-Score: {v4_f1:.4f}\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\"Error loading V4 model: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qwRQ3tiu7yG","executionInfo":{"status":"ok","timestamp":1765914990310,"user_tz":-60,"elapsed":12516,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"cad41ab6-7e92-4f01-f3ed-03783a93b7bf"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded ResNet50 V4: /content/drive/MyDrive/Galaxy_Morphology_Project/models/resnet50_best_dropout_v4.keras\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step\n","\n","--- RESNET50 V4 PERFORMANCE (128x128) ---\n","Weighted F1-Score: 0.0193\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000       162\n","           1     0.0000    0.0000    0.0000       278\n","           2     0.0000    0.0000    0.0000       397\n","           3     0.0000    0.0000    0.0000       304\n","           4     0.0000    0.0000    0.0000        50\n","           5     0.0000    0.0000    0.0000       307\n","           6     0.1032    1.0000    0.1872       274\n","           7     0.0000    0.0000    0.0000       394\n","           8     0.0000    0.0000    0.0000       214\n","           9     0.0000    0.0000    0.0000       281\n","\n","    accuracy                         0.1030      2661\n","   macro avg     0.0103    0.1000    0.0187      2661\n","weighted avg     0.0106    0.1030    0.0193      2661\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# CORRECTED EVALUATION Resnet50 dropout\n","try:\n","    print(\"Re-evaluating V4 with correct preprocessing...\")\n","    # Convert values back to the 0–255 range and apply ResNet preprocessing\n","    X_test_v4_ready = resnet_preprocess(X_test_128 * 255.0)\n","\n","    y_pred_probs = model_resnet_v4.predict(X_test_v4_ready, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(f\"Corrected Weighted F1-Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n","except Exception as e:\n","    print(f\"Error: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKV1g10W3SDz","executionInfo":{"status":"ok","timestamp":1765917177974,"user_tz":-60,"elapsed":2009,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"57f33437-d69d-4ef0-d3d7-94f068d84f80"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Re-evaluating V4 with correct preprocessing...\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n","Corrected Weighted F1-Score: 0.7559\n"]}]},{"cell_type":"markdown","source":["\n","## Experiment 5: Overcoming Instability with Data Augmentation and Class Balancing\n","\n","**Dynamic Augmentation:** Using ImageDataGenerator for 360-degree rotations and flips to help the model learn rotation-invariant galaxy features.\n","\n","**Manual Class Weighting:** Calculating precise weights to force the model to pay attention to rare galaxy types.\n","\n","**Native Keras Format:** Switched to .keras saving for better architectural stability.\n","\n","**Architecture:** Standard ResNet50 with a GlobalAveragePooling2D head (no extra Dense layers to minimize parameters).\n","\n","**Training Strategy:** Full model fine-tuning from the start with a very low Learning Rate ($1e-5$).\n","\n","**Optimization:** 10 Epochs using the val_loss monitor to capture the most stable state.\n","\n","**Data Handling:** 128x128 resolution, heavy ImageNet-style augmentation, and balanced class weights.\n","\n","**Result:** This model achieved significantly better stability and was chosen for the final Ensemble."],"metadata":{"id":"kW-XHYYs0OOa"}},{"cell_type":"code","source":["# DATA PREPARATION & AUGMENTATION SETUP\n","\n","# 1. Image Resizing to 128x128\n","# We use X_train, X_val, X_test which were defined in the first Data Loading cell\n","TARGET_SIZE = 128\n","\n","X_train_128 = np.array([cv2.resize(img, (TARGET_SIZE, TARGET_SIZE)) for img in X_train])\n","X_val_128 = np.array([cv2.resize(img, (TARGET_SIZE, TARGET_SIZE)) for img in X_val])\n","X_test_128 = np.array([cv2.resize(img, (TARGET_SIZE, TARGET_SIZE)) for img in X_test])\n","\n","# 2. Class Weight Calculation\n","y_train_labels = np.argmax(y_train_ohe, axis=1)\n","weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n","FINAL_CLASS_WEIGHTS = {i: weights[i] for i in range(len(weights))}\n","\n","# 3. Augmentation Pipeline\n","train_datagen = ImageDataGenerator(\n","    preprocessing_function=resnet_preprocess,\n","    rotation_range=360,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    zoom_range=0.1,\n","    fill_mode='nearest'\n",")\n","\n","# we mltiply by 255.0 as resnet_preprocess expects raw pixel values\n","train_generator = train_datagen.flow(X_train_128 * 255.0, y_train_ohe, batch_size=32)\n","\n","print(\"Data generators and Class Weights are ready using correct variable names.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtOWiMPO0ZEt","executionInfo":{"status":"ok","timestamp":1765916451840,"user_tz":-60,"elapsed":5891,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"1c834947-3936-46e3-d9b8-c6ce7d614c77"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Data generators and Class Weights are ready using correct variable names.\n"]}]},{"cell_type":"code","source":["# File: resnet50_best_final_chance.keras\n","\n","from tensorflow.keras.models import load_model\n","\n","MODEL_PATH = os.path.join(MODEL_DIR, 'resnet50_best_final_chance.keras')\n","\n","try:\n","    # Load the model that achieved stability\n","    final_resnet_model = load_model(MODEL_PATH)\n","    print(f\"Successfully loaded: {MODEL_PATH}\")\n","\n","    # Process test data\n","    X_test_processed = resnet_preprocess(X_test_128 * 255.0)\n","\n","    # Predict\n","    y_pred = np.argmax(final_resnet_model.predict(X_test_processed), axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- RESNET50 FINAL CHANCE PERFORMANCE ---\")\n","    f1_res = f1_score(y_true, y_pred, average='weighted')\n","    print(f\"Weighted F1-Score: {f1_res:.4f}\")\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\" Error: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GVrnTYo0s6i","executionInfo":{"status":"ok","timestamp":1765916488128,"user_tz":-60,"elapsed":18119,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"3cdf9cc2-6a99-4bc3-927b-310022f612fd"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded: /content/drive/MyDrive/Galaxy_Morphology_Project/models/resnet50_best_final_chance.keras\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step\n","\n","--- RESNET50 FINAL CHANCE PERFORMANCE ---\n","Weighted F1-Score: 0.7673\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.4633    0.5062    0.4838       162\n","           1     0.8217    0.7626    0.7910       278\n","           2     0.8278    0.9446    0.8824       397\n","           3     0.8386    0.8717    0.8548       304\n","           4     0.4500    0.9000    0.6000        50\n","           5     0.7958    0.7492    0.7718       307\n","           6     0.6571    0.7482    0.6997       274\n","           7     0.7210    0.5051    0.5940       394\n","           8     0.9038    0.8785    0.8910       214\n","           9     0.9044    0.8754    0.8897       281\n","\n","    accuracy                         0.7693      2661\n","   macro avg     0.7384    0.7741    0.7458      2661\n","weighted avg     0.7762    0.7693    0.7673      2661\n","\n"]}]},{"cell_type":"markdown","source":["# 3. DenseNet121\n","\n","This model was used in the latest aricles of the researchers working with this data. However sometimes the F1 score was not stated in their results, so I tried conduct my own experiments."],"metadata":{"id":"TspjedIvRsP-"}},{"cell_type":"code","source":["NUM_CLASSES = 10\n","\n","# input size 128x128\n","base_model_densenet = DenseNet121(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(128, 128, 3)\n",")\n","\n","base_model_densenet.trainable = True # all layers were unfrozen for fine-tuning\n","\n","# Custom Classifier Head\n","x = base_model_densenet.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dropout(0.3)(x)\n","predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n","\n","model_densenet_final = Model(inputs=base_model_densenet.input, outputs=predictions)\n","\n","# The model was compiled with the standard low Learning Rate for fine-tuning.\n","model_densenet_final.compile(\n","    optimizer=Adam(learning_rate=1e-5),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","BEST_MODEL_DENSENET_PATH = os.path.join(DRIVE_PATH, 'models', 'densenet121_best_final_v5.keras')\n","print(\"DenseNet121 Model Architecture defined.\")\n","print(f\"Final Model was saved to: {BEST_MODEL_DENSENET_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0FHfGFFkJ64","executionInfo":{"status":"ok","timestamp":1765913845014,"user_tz":-60,"elapsed":1759,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"e7fc17e2-c610-43ef-b1d0-a23df2fa933f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["DenseNet121 Model Architecture defined.\n","Final Model was saved to: /content/drive/MyDrive/Galaxy_Morphology_Project/models/densenet121_best_final_v5.keras\n"]}]},{"cell_type":"code","source":["# EVALUATION DENSENET121 MODEL\n","try:\n","    DENSENET_MODEL = load_model(BEST_MODEL_DENSENET_PATH)\n","    print(f\"Successfully loaded saved DenseNet121 model.\")\n","except Exception as e:\n","    print(f\"ERROR loading model. Check path: {BEST_MODEL_DENSENET_PATH}. Error: {e}\")\n","    exit()\n","\n","# We must resize it back to 128x128 for a fair comparison.\n","TARGET_SIZE_DENSENET = 128\n","X_test_densenet_input = np.array([cv2.resize(img, (TARGET_SIZE_DENSENET, TARGET_SIZE_DENSENET)) for img in X_test])\n","X_test_raw255_densenet = X_test_densenet_input * 255.0\n","\n","# Prediction (using ResNet Preprocessor, which works for DenseNet)\n","X_test_processed = resnet_preprocess(X_test_raw255_densenet)\n","y_pred_probs = DENSENET_MODEL.predict(X_test_processed)\n","\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","y_true = np.argmax(y_test_ohe, axis=1) # Using y_test_ohe from the Data Split section\n","\n","final_f1_densenet = f1_score(y_true, y_pred, average='weighted')\n","\n","print(\"\\n--- DENSENET121 EXPERIMENT EVALUATION ---\")\n","print(f\" Weighted F1-score (DenseNet121 @ 128x128): {final_f1_densenet:.4f}\")\n","print(\"--- Classification Report ---\")\n","print(classification_report(y_true, y_pred, digits=4, zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbT7j9c5kr_y","executionInfo":{"status":"ok","timestamp":1765912731986,"user_tz":-60,"elapsed":27803,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"472ca7f8-e1e0-4acc-8976-6a0b10f56a05"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded saved DenseNet121 model.\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 136ms/step\n","\n","--- DENSENET121 EXPERIMENT EVALUATION ---\n"," Weighted F1-score (DenseNet121 @ 128x128): 0.7507\n","--- Classification Report ---\n","              precision    recall  f1-score   support\n","\n","           0     0.3641    0.4877    0.4169       162\n","           1     0.7887    0.8058    0.7972       278\n","           2     0.8300    0.9471    0.8847       397\n","           3     0.8835    0.7730    0.8246       304\n","           4     0.4752    0.9600    0.6358        50\n","           5     0.7240    0.7264    0.7252       307\n","           6     0.6931    0.7007    0.6969       274\n","           7     0.6870    0.4569    0.5488       394\n","           8     0.9061    0.9019    0.9040       214\n","           9     0.8964    0.8932    0.8948       281\n","\n","    accuracy                         0.7520      2661\n","   macro avg     0.7248    0.7653    0.7329      2661\n","weighted avg     0.7624    0.7520    0.7507      2661\n","\n"]}]},{"cell_type":"markdown","source":["#4. EfficientNetB5 - High-Resolution Training (224x224) and EfficientNetB5\n","\n","To reach the next level of accuracy, I tried EfficientNetB5, a model known for its superior scaling and efficiency.\n","\n","**Changes:** Increased input resolution from 128x128 to 224x224 to capture finer morphological details of galaxies.\n","\n","**Preprocessing:** Switched to efficientnet_preprocess (critical for this architecture).\n","\n","**Training:** Full fine-tuning for 15 epochs with a very low learning rate ($1e-5$).\n","\n","**Data Strategy:** Applied heavy augmentation and re-calculated balanced class weights for the 224x224 dataset."],"metadata":{"id":"I-KsD5nm5Bua"}},{"cell_type":"code","source":["# EFFICIENTNETB5 SETUP & RE-SIZING\n","\n","TARGET_SIZE = 224\n","\n","# Re-sizing to the optimal resolution for B5\n","# Assuming X_train, X_val, X_test are our base [0, 1] arrays\n","X_train_224 = np.array([cv2.resize(img, (TARGET_SIZE, TARGET_SIZE)) for img in X_train])\n","X_val_224 = np.array([cv2.resize(img, (TARGET_SIZE, TARGET_SIZE)) for img in X_val])\n","X_test_224 = np.array([cv2.resize(img, (TARGET_SIZE, TARGET_SIZE)) for img in X_test])\n","\n","# Architecture matching the V6 experiment\n","base_model_effnet = EfficientNetB5(weights='imagenet', include_top=False, input_shape=(TARGET_SIZE, TARGET_SIZE, 3))\n","base_model_effnet.trainable = True\n","\n","x = GlobalAveragePooling2D()(base_model_effnet.output)\n","predictions = Dense(10, activation='softmax')(x)\n","\n","model_effnet_v6 = Model(inputs=base_model_effnet.input, outputs=predictions)\n","model_effnet_v6.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","print(f\"EfficientNetB5 architecture prepared for {TARGET_SIZE}x{TARGET_SIZE} inputs.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cW7aM6l5OOn","executionInfo":{"status":"ok","timestamp":1765917671849,"user_tz":-60,"elapsed":18953,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"26de7da4-c4b8-419a-9d8e-c0e8388b81c0"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n","\u001b[1m115263384/115263384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","EfficientNetB5 architecture prepared for 224x224 inputs.\n"]}]},{"cell_type":"code","source":["# EVALUATING THE V6 RECORD MODEL\n","\n","# File: efficientnetb5_best_final_v6.keras\n","\n","V6_PATH = os.path.join(MODEL_DIR, 'efficientnetb5_best_final_v6.keras')\n","\n","try:\n","    # Load the best state of B5\n","    model_effnet_v6 = load_model(V6_PATH)\n","    print(f\"Successfully loaded EfficientNetB5 V6: {V6_PATH}\")\n","\n","    # predict using the specialized EfficientNet preprocessor on [0, 255] data\n","    X_test_v6_ready = efficientnet_preprocess(X_test_224 * 255.0)\n","\n","    y_pred_probs = model_effnet_v6.predict(X_test_v6_ready, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- EFFICIENTNETB5 V6 PERFORMANCE (224x224) ---\")\n","    v6_f1 = f1_score(y_true, y_pred, average='weighted')\n","    print(f\"Record Weighted F1-Score: {v6_f1:.4f}\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\"Error loading V6: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4r1DlQl5Rm2","executionInfo":{"status":"ok","timestamp":1765917982579,"user_tz":-60,"elapsed":35338,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"e1fae368-4561-40eb-938f-35a3056ccf28"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded EfficientNetB5 V6: /content/drive/MyDrive/Galaxy_Morphology_Project/models/efficientnetb5_best_final_v6.keras\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 178ms/step\n","\n","--- EFFICIENTNETB5 V6 PERFORMANCE (224x224) ---\n","Record Weighted F1-Score: 0.7990\n","              precision    recall  f1-score   support\n","\n","           0     0.4162    0.5062    0.4568       162\n","           1     0.8496    0.8129    0.8309       278\n","           2     0.9062    0.9244    0.9152       397\n","           3     0.9307    0.8388    0.8824       304\n","           4     0.6104    0.9400    0.7402        50\n","           5     0.7969    0.8436    0.8196       307\n","           6     0.6676    0.8358    0.7423       274\n","           7     0.7674    0.5025    0.6074       394\n","           8     0.8943    0.9486    0.9206       214\n","           9     0.9170    0.9431    0.9298       281\n","\n","    accuracy                         0.8008      2661\n","   macro avg     0.7756    0.8096    0.7845      2661\n","weighted avg     0.8102    0.8008    0.7990      2661\n","\n"]}]},{"cell_type":"markdown","source":["# 6. The DLR Simulation (V7)\n","\n","Then I decided to do some \"polishing\" of the last experiment, so I re-compiled the model with an even lower Learning Rate      \n","($3 \\times 10^{-6}$).\n","\n","**Logic:** This acts as a manual Learning Rate Decay. It allows the model to adjust the weights of the classification head more precisely without distorting the well-trained feature extractors in the base EfficientNet layers. 5 final epochs to capture the absolute minimum validation loss."],"metadata":{"id":"gesmVYkX6YEZ"}},{"cell_type":"code","source":["#  EVALUATING THE DLR-REFINED MODEL\n","\n","\n","# Hyperparameters:\n","# - Base LR: 3e-6 (Ultra-low for precision)\n","# - Epochs: 5 (Extra)\n","# - File: efficientnetb5_dlr_final_v7.keras\n","\n","V7_PATH = os.path.join(MODEL_DIR, 'efficientnetb5_dlr_final_v7.keras')\n","\n","try:\n","    model_effnet_v7 = load_model(V7_PATH)\n","    print(f\"Successfully loaded DLR-refined EfficientNetB5: {V7_PATH}\")\n","\n","    # Predict (using the same 224x224 processed test set from Step 5.1)\n","    # X_test_v6_ready (from previous cell) is already 224x224 and preprocessed\n","    y_pred_probs = model_effnet_v7.predict(X_test_v6_ready, verbose=1)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","    y_true = np.argmax(y_test_ohe, axis=1)\n","\n","    print(\"\\n--- EFFICIENTNETB5 V7 (DLR) PERFORMANCE ---\")\n","    v7_f1 = f1_score(y_true, y_pred, average='weighted')\n","    print(f\"DLR Final Weighted F1-Score: {v7_f1:.4f}\")\n","\n","    # Comparison with V6\n","    improvement = v7_f1 - v6_f1\n","    print(f\"Delta from refinement: {improvement:+.4f}\")\n","\n","    print(\"\\nDetailed classification of morphologies (DLR Optimized):\")\n","    print(classification_report(y_true, y_pred, digits=4))\n","\n","except Exception as e:\n","    print(f\"Error loading V7: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"91EABWmB6d77","executionInfo":{"status":"ok","timestamp":1765918028557,"user_tz":-60,"elapsed":41282,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"1a5ff557-9029-4bb3-8c00-f967af9cc115"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded DLR-refined EfficientNetB5: /content/drive/MyDrive/Galaxy_Morphology_Project/models/efficientnetb5_dlr_final_v7.keras\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 178ms/step\n","\n","--- EFFICIENTNETB5 V7 (DLR) PERFORMANCE ---\n","DLR Final Weighted F1-Score: 0.8057\n","Delta from refinement: +0.0067\n","\n","Detailed classification of morphologies (DLR Optimized):\n","              precision    recall  f1-score   support\n","\n","           0     0.4159    0.5494    0.4734       162\n","           1     0.8667    0.8417    0.8540       278\n","           2     0.9089    0.9295    0.9191       397\n","           3     0.9066    0.8618    0.8836       304\n","           4     0.6765    0.9200    0.7797        50\n","           5     0.8377    0.8241    0.8309       307\n","           6     0.6705    0.8540    0.7512       274\n","           7     0.7846    0.4898    0.6031       394\n","           8     0.9009    0.9346    0.9174       214\n","           9     0.9119    0.9573    0.9340       281\n","\n","    accuracy                         0.8076      2661\n","   macro avg     0.7880    0.8162    0.7946      2661\n","weighted avg     0.8183    0.8076    0.8057      2661\n","\n"]}]},{"cell_type":"markdown","source":["# 7. Ensemble Learning\n","\n","\n","Then I thought since models have different \"blind spots\", by combining predictions from our best ResNet50 and EfficientNetB5, I can cancel out individual errors and boost overall stability.\n","\n","#### 2-Way Weighted Ensemble: ResNet50 (128x128) + EfficientNetB5 (224x224)."],"metadata":{"id":"fP368JHn7Xlu"}},{"cell_type":"code","source":["#  RESNET50 + EFFNETB5\n","\n","RESNET_PATH = os.path.join(MODEL_DIR, 'resnet50_best_final_chance.keras')\n","EFFNET_PATH = os.path.join(MODEL_DIR, 'efficientnetb5_dlr_final_v7.keras')\n","\n","model_resnet = load_model(RESNET_PATH)\n","model_effnet = load_model(EFFNET_PATH)\n","\n","# 2. preparing data for ResNet50 (128x128)\n","X_test_128 = np.array([cv2.resize(img, (128, 128)) for img in X_test])\n","prob_resnet = model_resnet.predict(resnet_preprocess(X_test_128 * 255.0), verbose=1)\n","\n","# 3. for EfficientNetB5 (224x224)\n","X_test_224 = np.array([cv2.resize(img, (224, 224)) for img in X_test])\n","prob_effnet = model_effnet.predict(efficientnet_preprocess(X_test_224 * 255.0), verbose=1)\n","\n","# 4. weights\n","ENSEMBLE_WEIGHTS = [0.3, 0.7] # 30% ResNet, 70% EffNet\n","prob_ensemble = (prob_resnet * ENSEMBLE_WEIGHTS[0]) + (prob_effnet * ENSEMBLE_WEIGHTS[1])\n","\n","y_pred_ensemble = np.argmax(prob_ensemble, axis=1)\n","y_true = np.argmax(y_test_ohe, axis=1)\n","\n","final_f1 = f1_score(y_true, y_pred_ensemble, average='weighted')\n","\n","print(f\"\\n FINAL ENSEMBLE RESULT\")\n","print(f\"Weighted F1-Score: {final_f1:.4f}\")\n","print(f\"Improvement over Single Best Model: +{(final_f1 - 0.7990)*100:.2f}%\")\n","\n","print(\"\\n Detailed Report:\")\n","print(classification_report(y_true, y_pred_ensemble, digits=4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahcQX5Th6fAu","executionInfo":{"status":"ok","timestamp":1765918582368,"user_tz":-60,"elapsed":50305,"user":{"displayName":"яна бембеева","userId":"12193535455081206014"}},"outputId":"04e9785d-a73c-4323-d888-1ac6ae7697a0"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 179ms/step\n","\n"," FINAL ENSEMBLE RESULT\n","Weighted F1-Score: 0.8151\n","Improvement over Single Best Model: +1.61%\n","\n"," Detailed Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.4604    0.5741    0.5110       162\n","           1     0.8613    0.8489    0.8551       278\n","           2     0.8964    0.9370    0.9163       397\n","           3     0.9122    0.8882    0.9000       304\n","           4     0.6912    0.9400    0.7966        50\n","           5     0.8498    0.8111    0.8300       307\n","           6     0.6890    0.8650    0.7670       274\n","           7     0.7915    0.5203    0.6279       394\n","           8     0.9041    0.9252    0.9145       214\n","           9     0.9210    0.9537    0.9371       281\n","\n","    accuracy                         0.8174      2661\n","   macro avg     0.7977    0.8263    0.8055      2661\n","weighted avg     0.8251    0.8174    0.8151      2661\n","\n"]}]},{"cell_type":"markdown","source":["# Conclusion:\n","\n","Reaching the target accuracy of 0.85 would likely require moving to hybrid Transformer-based models (e.g., CvT), as shown in recent research. However, this transition would require much larger computational resources, access to large-scale pretraining datasets, and more complex training strategies."],"metadata":{"id":"LODNGzJQEYqG"}}]}